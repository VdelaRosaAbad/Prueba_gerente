#!/usr/bin/env python3
"""
ğŸ“Š Carga Directa a BigQuery (Alternativa a Dataflow)
â±ï¸  Tiempo estimado: 2-4 horas para 136GB
ğŸ’¡ Funciona SIN Dataflow, solo con BigQuery
ğŸš« Para cuando no puedes aumentar cuotas de Dataflow
"""

import subprocess
import time
import logging
from datetime import datetime

# ConfiguraciÃ³n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def run_bq_load():
    """Ejecuta carga directa a BigQuery usando bq load"""
    
    start_time = time.time()
    logger.info("ğŸš€ Iniciando carga directa a BigQuery...")
    logger.info("ğŸ’¡ Alternativa cuando Dataflow no estÃ¡ disponible")
    
    # Obtener proyecto actual
    try:
        project_id = subprocess.run(
            ['gcloud', 'config', 'get-value', 'project'], 
            capture_output=True, text=True, check=True
        ).stdout.strip()
    except subprocess.CalledProcessError:
        logger.error("âŒ No se pudo obtener el proyecto. Ejecuta: gcloud config set project TU_PROJECT_ID")
        return False
    
    logger.info(f"ğŸ“Š Proyecto: {project_id}")
    
    # ConfiguraciÃ³n de la carga
    dataset_name = "cdo_challenge"
    table_name = "raw_data"
    source_file = "gs://desafio-deacero-143d30a0-d8f8-4154-b7df-1773cf286d32/cdo_challenge.csv.gz"
    
    # Crear dataset si no existe
    logger.info(f"ğŸ—„ï¸ Creando dataset: {dataset_name}")
    try:
        subprocess.run([
            'bq', 'mk', '--dataset', f'{project_id}:{dataset_name}'
        ], check=False)  # No fallar si ya existe
        logger.info("âœ… Dataset creado/verificado")
    except Exception as e:
        logger.warning(f"âš ï¸  Error creando dataset: {e}")
    
    # Comando de carga optimizado
    load_command = [
        'bq', 'load',
        '--source_format=CSV',
        '--autodetect',  # Auto-detect schema
        '--ignore_unknown_values',
        '--max_bad_records=10000',  # Permitir hasta 10k registros malos
        '--replace',  # Reemplazar tabla si existe
        '--field_delimiter=,',
        '--skip_leading_rows=1',  # Saltar encabezado si existe
        '--allow_quoted_newlines',  # Permitir saltos de lÃ­nea en campos
        '--allow_jagged_rows',  # Permitir filas con diferente nÃºmero de columnas
        f'{project_id}:{dataset_name}.{table_name}',
        source_file
    ]
    
    logger.info("ğŸ“¤ Iniciando carga directa a BigQuery...")
    logger.info(f"ğŸ“ Archivo: {source_file}")
    logger.info(f"ğŸ“‹ Tabla: {project_id}:{dataset_name}.{table_name}")
    
    # Ejecutar carga
    try:
        result = subprocess.run(
            load_command,
            capture_output=True,
            text=True,
            check=True
        )
        
        end_time = time.time()
        duration = end_time - start_time
        
        logger.info("âœ… Â¡Carga completada exitosamente!")
        logger.info(f"â±ï¸  Tiempo total: {duration:.2f} segundos ({duration/60:.2f} minutos)")
        logger.info(f"ğŸ“Š Datos disponibles en: {project_id}:{dataset_name}.{table_name}")
        
        # Mostrar estadÃ­sticas de la tabla
        logger.info("ğŸ“ˆ Obteniendo estadÃ­sticas de la tabla...")
        stats_result = subprocess.run([
            'bq', 'show', '--format=json', f'{project_id}:{dataset_name}.{table_name}'
        ], capture_output=True, text=True, check=True)
        
        import json
        stats = json.loads(stats_result.stdout)
        num_rows = stats.get('numRows', 0)
        num_bytes = stats.get('numBytes', 0)
        
        logger.info(f"ğŸ“Š Filas cargadas: {num_rows:,}")
        logger.info(f"ğŸ’¾ TamaÃ±o: {num_bytes / (1024**3):.2f} GB")
        
        return True
        
    except subprocess.CalledProcessError as e:
        logger.error(f"âŒ Error en la carga: {e}")
        logger.error(f"ğŸ“ Error details: {e.stderr}")
        return False
    except Exception as e:
        logger.error(f"âŒ Error inesperado: {e}")
        return False

def check_bq_availability():
    """Verifica que bq estÃ© disponible"""
    try:
        result = subprocess.run(['bq', 'version'], capture_output=True, text=True)
        if result.returncode == 0:
            logger.info("âœ… BigQuery CLI disponible")
            return True
        else:
            logger.error("âŒ BigQuery CLI no disponible")
            return False
    except FileNotFoundError:
        logger.error("âŒ BigQuery CLI no encontrado. Instala Google Cloud SDK")
        return False

def main():
    """FunciÃ³n principal"""
    logger.info("ğŸ” VERIFICANDO DISPONIBILIDAD DE BIGQUERY")
    logger.info("=" * 60)
    
    if not check_bq_availability():
        logger.error("âŒ No se puede continuar sin BigQuery CLI")
        logger.info("ğŸ’¡ Instala: https://cloud.google.com/sdk/docs/install")
        return False
    
    logger.info("ğŸš€ INICIANDO CARGA DIRECTA A BIGQUERY")
    logger.info("=" * 60)
    logger.info("ğŸ’¡ Esta es una alternativa cuando Dataflow no estÃ¡ disponible")
    logger.info("â±ï¸  Tiempo estimado: 2-4 horas (mÃ¡s lento que Dataflow)")
    logger.info("âœ… Ventaja: Funciona sin restricciones de cuotas")
    logger.info("")
    
    # Confirmar con el usuario
    response = input("Â¿Continuar con la carga directa? (s/N): ").strip().lower()
    if response not in ['s', 'si', 'sÃ­', 'y', 'yes']:
        logger.info("âŒ Carga cancelada por el usuario")
        return False
    
    # Ejecutar carga
    success = run_bq_load()
    
    if success:
        logger.info("")
        logger.info("ğŸ‰ Â¡CARGA COMPLETADA EXITOSAMENTE!")
        logger.info("ğŸ’¡ Para futuras cargas rÃ¡pidas, considera:")
        logger.info("   â€¢ Solicitar aumento de cuotas de Dataflow")
        logger.info("   â€¢ Usar el pipeline optimizado para 8 IPs")
        logger.info("   â€¢ Contactar soporte de Google Cloud")
    else:
        logger.error("")
        logger.error("âŒ LA CARGA FALLÃ“")
        logger.error("ğŸ’¡ Alternativas:")
        logger.error("   â€¢ Revisar logs de error arriba")
        logger.error("   â€¢ Verificar permisos del proyecto")
        logger.error("   â€¢ Usar el pipeline optimizado para 8 IPs")
    
    return success

if __name__ == '__main__':
    main()
