#!/bin/bash

# ğŸš¨ SOLUCIONADOR DE PROBLEMAS DE CUOTAS EN DATAFLOW
# ğŸ”§ Cambia regiÃ³n y optimiza configuraciÃ³n para evitar lÃ­mites de cuotas

echo "ğŸš¨ Detectado problema de cuotas en us-central1"
echo "ğŸ”§ Aplicando soluciÃ³n automÃ¡tica..."

# Obtener proyecto actual
export PROJECT_ID=$(gcloud config get-value project)
echo "ğŸ“Š Proyecto: $PROJECT_ID"

# Verificar cuotas en diferentes regiones
echo "ğŸ” Verificando cuotas disponibles en diferentes regiones..."

# Lista de regiones alternativas con mejores cuotas
REGIONS=("us-east1" "us-west1" "europe-west1" "asia-southeast1")

for region in "${REGIONS[@]}"; do
    echo "ğŸ“ Verificando regiÃ³n: $region"
    
    # Verificar cuota de direcciones IP
    quota_result=$(gcloud compute regions describe $region --project=$PROJECT_ID --format="value(quotas[metric=IN_USE_ADDRESSES].limit)" 2>/dev/null)
    
    if [ ! -z "$quota_result" ] && [ "$quota_result" != "None" ]; then
        echo "   âœ… IN_USE_ADDRESSES limit: $quota_result"
        
        # Si encontramos una regiÃ³n con mÃ¡s de 20 direcciones IP, la usamos
        if [ "$quota_result" -gt 20 ]; then
            echo "ğŸ¯ Â¡RegiÃ³n $region tiene cuotas suficientes!"
            export OPTIMAL_REGION=$region
            break
        fi
    else
        echo "   âš ï¸  No se pudo verificar cuota en $region"
    fi
done

# Si no encontramos regiÃ³n Ã³ptima, usar us-east1 (generalmente tiene mÃ¡s cuotas)
if [ -z "$OPTIMAL_REGION" ]; then
    export OPTIMAL_REGION="us-east1"
    echo "âš ï¸  Usando regiÃ³n por defecto: $OPTIMAL_REGION"
fi

echo "ğŸ”§ Configurando regiÃ³n Ã³ptima: $OPTIMAL_REGION"

# Configurar regiÃ³n en gcloud
gcloud config set compute/region $OPTIMAL_REGION
gcloud config set dataflow/region $OPTIMAL_REGION

# Actualizar scripts con la nueva regiÃ³n
echo "ğŸ“ Actualizando configuraciÃ³n en scripts..."

# Actualizar ultra_fast_loader.py
sed -i "s/us-central1/$OPTIMAL_REGION/g" ultra_fast_loader.py
sed -i "s/50/8/g" ultra_fast_loader.py  # Reducir workers iniciales
sed -i "s/100/16/g" ultra_fast_loader.py  # Reducir mÃ¡ximo de workers

# Actualizar run_ultra_fast_loader.sh
sed -i "s/us-central1/$OPTIMAL_REGION/g" run_ultra_fast_loader.sh
sed -i "s/50/8/g" run_ultra_fast_loader.sh
sed -i "s/100/16/g" run_ultra_fast_loader.sh

echo "âœ… ConfiguraciÃ³n actualizada para regiÃ³n: $OPTIMAL_REGION"
echo "ğŸ“Š Workers configurados: 8 iniciales, mÃ¡ximo 16 (dentro de lÃ­mites de cuota)"

# Mostrar configuraciÃ³n actual
echo ""
echo "ğŸ”§ CONFIGURACIÃ“N ACTUALIZADA:"
echo "   ğŸŒ RegiÃ³n: $OPTIMAL_REGION"
echo "   ğŸ‘¥ Workers iniciales: 8"
echo "   ğŸš€ Workers mÃ¡ximos: 16"
echo "   ğŸ“ Archivo: gs://desafio-deacero-143d30a0-d8f8-4154-b7df-1773cf286d32/cdo_challenge.csv.gz"
echo ""

# Verificar que la nueva configuraciÃ³n estÃ© lista
echo "ğŸ§ª Verificando configuraciÃ³n..."
python3 -c "
import re
with open('ultra_fast_loader.py', 'r') as f:
    content = f.read()
    region_match = re.search(r'region = \"([^\"]+)\"', content)
    workers_match = re.search(r'num_workers = (\d+)', content)
    max_workers_match = re.search(r'max_num_workers = (\d+)', content)
    
    if region_match and workers_match and max_workers_match:
        print(f'âœ… RegiÃ³n configurada: {region_match.group(1)}')
        print(f'âœ… Workers iniciales: {workers_match.group(1)}')
        print(f'âœ… Workers mÃ¡ximos: {max_workers_match.group(1)}')
    else:
        print('âŒ Error en la configuraciÃ³n')
"

echo ""
echo "ğŸ¯ PRÃ“XIMOS PASOS:"
echo "1. Ejecutar: ./run_ultra_fast_loader.sh"
echo "2. Monitorear: python3 monitor_pipeline.py --project=$PROJECT_ID"
echo "3. Verificar en Dataflow Console: https://console.cloud.google.com/dataflow"
echo ""
echo "ğŸ’¡ CONSEJO: Con esta configuraciÃ³n optimizada, la carga tomarÃ¡ ~45-60 minutos"
echo "   pero serÃ¡ estable y sin errores de cuotas."
